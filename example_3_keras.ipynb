{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example_3_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtnman38/tensorflow-examples/blob/master/example_3_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl_Y7gLr_Nsr",
        "colab_type": "text"
      },
      "source": [
        "# Example 3: Using the Keras API!\n",
        "\n",
        "---\n",
        "\n",
        "Dustin A. Landers\n",
        "---\n",
        "11/5/2019\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvl6s3Z4_WHC",
        "colab_type": "text"
      },
      "source": [
        "Let's make sure we have the latest TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9fZW42O_kuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vacziy4Q-hhx",
        "colab_type": "code",
        "outputId": "65f34815-cf7a-4041-d7db-9e2a5012c157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGGKa1kYWQ2J",
        "colab_type": "text"
      },
      "source": [
        "## Dataset loading (how to get public dataset easily)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD7o2JhbAL6r",
        "colab_type": "text"
      },
      "source": [
        "Next we will bring in some fun datasets for us to work with. We will use the tensorflow_datasets package to go ahead and get a pre-loaded dataset. Fortunately, this will make it easy for us to get started with text architectures and using the keras module. Unforunately, it also will create a bit of illusion about how easy it is to get the data in the correct format. Per usual, preparing the data for a tensorflow task is often the most tedious part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwZJZQ1X_fDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4UIVsoCASVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_data, test_data), info = tfds.load(\n",
        "    'imdb_reviews/subwords8k', \n",
        "    split = (tfds.Split.TRAIN, tfds.Split.TEST),\n",
        "    as_supervised=True,\n",
        "    with_info=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew0wgJpWOX-v",
        "colab_type": "text"
      },
      "source": [
        "This tensorflow public dataset also comes with the text encoder. This saves us yet another step. I'm going to play around with that encoder below so that we have a chance to see how it works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR8j_m74WY0I",
        "colab_type": "text"
      },
      "source": [
        "## This is how encoders work!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-26XISxDpfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = info.features['text'].encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c4PjSnHEjYy",
        "colab_type": "code",
        "outputId": "66d1c8d5-168d-48eb-ce55-6cd7f7b4510c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "encoder.encode('man I really am enjoying using tensorflow 2.0!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[172,\n",
              " 12,\n",
              " 81,\n",
              " 258,\n",
              " 1236,\n",
              " 34,\n",
              " 1168,\n",
              " 943,\n",
              " 2327,\n",
              " 2934,\n",
              " 7961,\n",
              " 7979,\n",
              " 7975,\n",
              " 7977,\n",
              " 7962]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecrc4C-hNLoH",
        "colab_type": "code",
        "outputId": "3cbf92a3-2a6c-4812-ce40-8317347e003c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoder.decode([172, 12, 81, 258, 1236,\n",
        "                34, 1168, 943, 2327, 2934,\n",
        "                7961, 7979, 7975, 7977, 7962])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'man I really am enjoying using tensorflow 2.0!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6saRaEuOWczk",
        "colab_type": "text"
      },
      "source": [
        "## You train deep learning representations with batches (can you guess why?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkTQ8E4lF0GP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = (\n",
        "    train_data\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .padded_batch(32, train_data.output_shapes))\n",
        "\n",
        "test_batches = (\n",
        "    test_data\n",
        "    .padded_batch(32, train_data.output_shapes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhPaYWQYWlbJ",
        "colab_type": "text"
      },
      "source": [
        "## Use tf.keras.Sequential to build out layers (this one is simple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKku1awPWt4k",
        "colab_type": "text"
      },
      "source": [
        "### Example of cool architectures -- embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRap3QmJKOVG",
        "colab_type": "code",
        "outputId": "3d95b637-7712-4d99-977b-e1a1c755874b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(encoder.vocab_size, 16),\n",
        "  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          130960    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 130,977\n",
            "Trainable params: 130,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZi_hACuV1kH",
        "colab_type": "text"
      },
      "source": [
        "This architecture achieved decent accuracy on the validation set by epoch 10!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQd6vBmKV_Dr",
        "colab_type": "text"
      },
      "source": [
        "What if we used a more complex architecture. Maybe we use a 1-dimensional convultion layer to pick up on various word combinations and phrases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXqvm6R7KUzU",
        "colab_type": "code",
        "outputId": "adf3c4e3-894a-48a2-c4a7-bc3ee04cd123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=10,\n",
        "                    validation_data=test_batches,\n",
        "                    validation_steps=30)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.6813 - accuracy: 0.6316 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.6227 - accuracy: 0.7511 - val_loss: 0.5973 - val_accuracy: 0.7823\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.5446 - accuracy: 0.8065 - val_loss: 0.5315 - val_accuracy: 0.8031\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.4785 - accuracy: 0.8378 - val_loss: 0.4779 - val_accuracy: 0.8448\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.4257 - accuracy: 0.8624 - val_loss: 0.4363 - val_accuracy: 0.8521\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.3858 - accuracy: 0.8754 - val_loss: 0.4043 - val_accuracy: 0.8635\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.3521 - accuracy: 0.8854 - val_loss: 0.3795 - val_accuracy: 0.8687\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.3290 - accuracy: 0.8917 - val_loss: 0.3596 - val_accuracy: 0.8729\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.3065 - accuracy: 0.8982 - val_loss: 0.3442 - val_accuracy: 0.8792\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.2885 - accuracy: 0.9039 - val_loss: 0.3309 - val_accuracy: 0.8844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnXmZz-s7oTr",
        "colab_type": "text"
      },
      "source": [
        "## Don't stop here. There are tons of cool architectures to explore to improve upon the accuracy achieved above."
      ]
    }
  ]
}